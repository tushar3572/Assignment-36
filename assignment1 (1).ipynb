{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee90c27-78f4-4a71-a6bd-e731ae94794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 1\n",
    "    \n",
    "The k-nearest neighbors (KNN) algorithm is a non-parametric, supervised learning classifier, which uses proximity \n",
    "to make classifications or predictions about the grouping of an individual data point. \n",
    "It is one of the popular and simplest classification and regression classifiers used in machine learning today.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352734cd-0f47-44f2-b74c-96ec1f957b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 2\n",
    "    \n",
    "Lower values of k can have high variance, but low bias, and larger values of k may lead to high bias and \n",
    "lower variance. The choice of k will largely depend on the input data as data with more outliers or noise will\n",
    "likely perform better with higher values of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2d3a6-35ed-4e43-a144-c739f1dabfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 3\n",
    "    \n",
    "KNN regression tries to predict the value of the output variable by using a local average.\n",
    "KNN classification attempts to predict the class to which the output variable belong by computing the local probability.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9853ef-bd73-4b93-b39a-02960122db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 4\n",
    "    \n",
    "The test data is used to evaluate the performance of the model. The model is tested on the test data by using it to make predictions and comparing these predictions to the actual target values.\n",
    "When training a kNN classifier, it's essential to normalize the features.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89127b5f-bcd1-4d07-8fe9-f1148fa9bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 5\n",
    "    \n",
    "The “Curse of Dimensionality” is a tongue in cheek way of stating that there's a ton of space in high-dimensional data sets.\n",
    "The size of the data space grows exponentially with the number of dimensions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf475d02-bd00-4f9d-88b8-3170f3aa189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 6\n",
    "    \n",
    "The idea in kNN methods is to identify 'k' samples in the dataset that are similar or close in the space. \n",
    "Then we use these 'k' samples to estimate the value of the missing data points.\n",
    "Each sample's missing values are imputed using the mean value of the 'k'-neighbors found in the dataset.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ab4bcf-a3dd-4b35-a526-b5b83887597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 7\n",
    "    \n",
    "The KNN algorithm for classification will look at the k nearest neighbours of the input you are trying to make\n",
    "a prediction on. It will then output the most frequent label among those k examples.\n",
    "In regression tasks, the user wants to output a numerical value (usually continuous).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85603164-3eeb-4678-bfba-24c6db539b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 8\n",
    "    \n",
    "-Few hyperparameters: KNN only requires a k value and a distance metric, which is low when compared to other\n",
    "machine learning algorithms. \n",
    "- Does not scale well: Since KNN is a lazy algorithm, it takes up more memory and data storage compared to other \n",
    "classifiers.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe9417-d38c-430f-9f5e-e8ac1d8c1642",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 9\n",
    "    \n",
    "Euclidean distance is the shortest path between source and destination which is a straight line \n",
    "but Manhattan distance is sum of all the real distances between source(s) and destination(d) and each distance are always the straight lines     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e23956-5166-471e-bfc4-9afc8d0378b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 10\n",
    "    \n",
    "To put it simply, yes, feature scaling is crucial for the KNN algorithm, as it helps in preventing features with larger magnitudes from dominating the distance calculations.\n",
    "Feature scaling is an essential step in the data preprocessing pipeline, especially for distance-based algorithms like the KNN.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
